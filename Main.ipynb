{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It consists of the repeated\n",
    "application of two 3x3 convolutions (unpadded convolutions), each followed by\n",
    "a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2\n",
    "for downsampling. At each downsampling step we double the number of feature\n",
    "channels. Every step in the expansive path consists of an upsampling of the\n",
    "feature map followed by a 2x2 convolution (“up-convolution”) that halves the\n",
    "number of feature channels, a concatenation with the correspondingly cropped\n",
    "feature map from the contracting path, and two 3x3 convolutions, each followed\n",
    "by a ReLU. The cropping is necessary due to the loss of border pixels in\n",
    "every convolution. At the final layer a 1x1 convolution is used to map each 64-\n",
    "component feature vector to the desired number of classes. In total the network\n",
    "has 23 convolutional layers.\n",
    "To allow a seamless tiling of the output segmentation map (see Figure 2), it\n",
    "is important to select the input tile size such that all 2x2 max-pooling operations\n",
    "are applied to a layer with an even x- and y-size.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import \n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, merge,UpSampling2D, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "# from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_convolutional( X, f, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window - deep\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    mp_name_base = 'mp' + str(stage) + block + '_branch'\n",
    "    \n",
    "    \n",
    "    # First component of convolutional block\n",
    "    X = Conv2D(f, (3,3), strides = (1,1), padding = 'same', name = conv_name_base + '1a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '1a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of convolutional block\n",
    "    X = Conv2D(f, (3,3), strides = (1,1), padding = 'same', name = conv_name_base + '1b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '1b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unetModel(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the UNet.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    #input (572*572*1)\n",
    "    X_Input = Input(input_shape)\n",
    "\n",
    "    # Stage 1\n",
    "    X1 = double_convolutional( X_Input, 64, 1)\n",
    "    X1 = MaxPooling2D(pool_size=(2, 2), strides=2,name='mp1')(X1) \n",
    "\n",
    "    # Stage 2\n",
    "    X2 = double_convolutional( X1, 128, 2)\n",
    "    X2 = MaxPooling2D(pool_size=(2, 2), strides=2,name='mp2')(X2) \n",
    "\n",
    "    # Stage 3\n",
    "    X3 = double_convolutional( X2, 256, 3)\n",
    "    X3 = MaxPooling2D(pool_size=(2, 2), strides=2,name='mp3')(X3) \n",
    "\n",
    "    # Stage 4\n",
    "    X4 = double_convolutional( X3, 512, 4)\n",
    "    X4 = MaxPooling2D(pool_size=(2, 2), strides=2,name='mp4')(X4) \n",
    "\n",
    "    # Stage 5\n",
    "    X = double_convolutional( X4, 1024, 5)\n",
    "\n",
    "    X = UpSampling2D(size = (2,2))(X)\n",
    "\n",
    "    X = Conv2D(f, (3,3), strides = (1,1), padding = 'same', name = 'res6', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "\n",
    "    X = merge([X4,X], mode = 'concat', concat_axis = 3)\n",
    "\n",
    "    X = double_convolutional( X, 512, 7)\n",
    "\n",
    "    X = UpSampling2D(size = (2,2))(X)\n",
    "\n",
    "\n",
    "\n",
    "    X = Conv2D(f, (3,3), strides = (1,1), padding = 'same', name = 'res7', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "\n",
    "    X = merge([X3,X], mode = 'concat', concat_axis = 3)\n",
    "\n",
    "    X = double_convolutional( X, 256, 8)\n",
    "\n",
    "    X = UpSampling2D(size = (2,2))(X)\n",
    "\n",
    "\n",
    "    X = Conv2D(f, (3,3), strides = (1,1), padding = 'same', name = 'res8', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "\n",
    "    X = merge([X2,X], mode = 'concat', concat_axis = 3)\n",
    "\n",
    "    X = double_convolutional( X, 128, 9)\n",
    "\n",
    "    X = UpSampling2D(size = (2,2))(X)\n",
    "\n",
    "    X = Conv2D(f, (3,3), strides = (1,1), padding = 'same', name = 'res9', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "\n",
    "    X = merge([X1,X], mode = 'concat', concat_axis = 3)\n",
    "\n",
    "    X = double_convolutional( X, 64, 9)\n",
    "\n",
    "    \n",
    "    X = Conv2D(f, (1,1), strides = (1,1), padding = 'same', name = 'res10', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
